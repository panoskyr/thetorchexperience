{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchvision\n!pip install torcheval\n!pip install torchmetrics\n!git clone https://github.com/panoskyr/thetorchexperience.git\n%cd thetorchexperience\n","metadata":{"id":"0fY79mDfGBML","execution":{"iopub.status.busy":"2023-06-26T16:42:22.973001Z","iopub.execute_input":"2023-06-26T16:42:22.973270Z","iopub.status.idle":"2023-06-26T16:43:05.724404Z","shell.execute_reply.started":"2023-06-26T16:42:22.973247Z","shell.execute_reply":"2023-06-26T16:43:05.722701Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.0.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting torcheval\n  Downloading torcheval-0.0.6-py3-none-any.whl (158 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.4/158.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting torchtnt>=0.0.5 (from torcheval)\n  Downloading torchtnt-0.1.0-py3-none-any.whl (87 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.5.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (2.0.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (1.23.5)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (2023.6.0)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (2.12.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (5.9.3)\nCollecting pyre-extensions (from torchtnt>=0.0.5->torcheval)\n  Downloading pyre_extensions-0.0.30-py3-none-any.whl (12 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (59.8.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtnt>=0.0.5->torcheval) (4.64.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->torchtnt>=0.0.5->torcheval) (3.0.9)\nRequirement already satisfied: typing-inspect in /opt/conda/lib/python3.10/site-packages (from pyre-extensions->torchtnt>=0.0.5->torcheval) (0.9.0)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.4.3)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.28.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.3.6)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.40.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchtnt>=0.0.5->torcheval) (3.12.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchtnt>=0.0.5->torcheval) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.2.7)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (1.16.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchtnt>=0.0.5->torcheval) (1.3.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect->pyre-extensions->torchtnt>=0.0.5->torcheval) (1.0.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (3.2.2)\nInstalling collected packages: pyre-extensions, torchtnt, torcheval\nSuccessfully installed pyre-extensions-0.0.30 torcheval-0.0.6 torchtnt-0.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (0.11.4)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.23.5)\nRequirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.0.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->torchmetrics) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCloning into 'thetorchexperience'...\nremote: Enumerating objects: 190, done.\u001b[K\nremote: Counting objects: 100% (190/190), done.\u001b[K\nremote: Compressing objects: 100% (140/140), done.\u001b[K\nremote: Total 190 (delta 119), reused 106 (delta 47), pack-reused 0\u001b[K\nReceiving objects: 100% (190/190), 7.93 MiB | 8.86 MiB/s, done.\nResolving deltas: 100% (119/119), done.\n/kaggle/working/thetorchexperience\n","output_type":"stream"}]},{"cell_type":"code","source":"%mkdir '/kaggle/working/t_models/'","metadata":{"execution":{"iopub.status.busy":"2023-06-26T16:43:36.638299Z","iopub.execute_input":"2023-06-26T16:43:36.638663Z","iopub.status.idle":"2023-06-26T16:43:37.601084Z","shell.execute_reply.started":"2023-06-26T16:43:36.638630Z","shell.execute_reply":"2023-06-26T16:43:37.599857Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport glob\nfrom pprint import pprint\nfrom skimage.io import imread\nfrom torch.utils.data import DataLoader\nimport thetorchexperience.utils\nfrom thetorchexperience.models import HumerusDataset, BaselineNN, HistEqualizationTransform,class6_Dataset, ResnetTransfer,class2_Dataset, get_loaders\nimport torch\nfrom torch import nn\nimport torchvision\nimport torcheval\nfrom torcheval.metrics import BinaryAccuracy\nfrom tqdm.notebook import tqdm\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f'Pytorch version: {torch.__version__}, Torchvision version: {torchvision.__version__}, device is : {device}')\nmurapath='/kaggle/input/mura-v11/MURA-v1.1/'\ncodepath='/kaggle/working/thetorchexperience/'\ncsvpath='/kaggle/input/mura-v11'","metadata":{"id":"vQSgade6F6bs","outputId":"f1402e0f-3e96-461e-93b6-e1168240b809","execution":{"iopub.status.busy":"2023-06-26T16:43:40.809278Z","iopub.execute_input":"2023-06-26T16:43:40.809655Z","iopub.status.idle":"2023-06-26T16:43:45.368579Z","shell.execute_reply.started":"2023-06-26T16:43:40.809620Z","shell.execute_reply":"2023-06-26T16:43:45.367589Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Pytorch version: 2.0.0, Torchvision version: 0.15.1, device is : cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"everythingScans_df=pd.read_csv(os.path.join(codepath,'everythingScans_df.csv'))\neverythingScans_df['path']=murapath+everythingScans_df['path']\neverythingScans_df['path']=everythingScans_df['path'].replace({r'\\\\':'/'},regex=True)","metadata":{"id":"-Sty72DZG1ZE","execution":{"iopub.status.busy":"2023-06-26T18:46:22.461787Z","iopub.execute_input":"2023-06-26T18:46:22.462149Z","iopub.status.idle":"2023-06-26T18:46:22.716037Z","shell.execute_reply.started":"2023-06-26T18:46:22.462119Z","shell.execute_reply":"2023-06-26T18:46:22.715001Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"We check if some data is missing","metadata":{"id":"V4_KYTWEF6b1"}},{"cell_type":"code","source":"print(everythingScans_df.isnull().values.any())\na=[0 if (x=='positive' or x=='negative') else 1 for x in everythingScans_df['Label'] ]\nprint(sum(a))","metadata":{"id":"49aN-dyHF6b1","outputId":"31d999b4-34e5-41e8-ba4f-7d6795e0a493","execution":{"iopub.status.busy":"2023-06-26T13:05:15.115691Z","iopub.execute_input":"2023-06-26T13:05:15.116041Z","iopub.status.idle":"2023-06-26T13:05:15.213828Z","shell.execute_reply.started":"2023-06-26T13:05:15.116008Z","shell.execute_reply":"2023-06-26T13:05:15.212883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\neverythingScans_df['Bone'].hist(bins=range(0,9),rwidth=1, align='left',edgecolor='black')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"id":"62gGSNC0F6b2","outputId":"3dee6257-0f07-4bb6-88fe-7d60b092aed9","execution":{"iopub.status.busy":"2023-06-26T13:05:15.215323Z","iopub.execute_input":"2023-06-26T13:05:15.215694Z","iopub.status.idle":"2023-06-26T13:05:15.509421Z","shell.execute_reply.started":"2023-06-26T13:05:15.215663Z","shell.execute_reply":"2023-06-26T13:05:15.508555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explore some examples of images\nWhen groupping by two values we need to define how the values will be combined.\nget combinations of pics with same label and bone then choose one randomly","metadata":{"id":"0lYgmF5rF6b3"}},{"cell_type":"code","source":"onePairPic_df=everythingScans_df.groupby(['Label','Bone']).apply(lambda x:x.sample(1))\nonePairPic_df.reset_index(drop=True)","metadata":{"id":"1vAScQGiF6b3","outputId":"ac0b6be6-7adc-45a9-8b1a-0de4a780cdf2","execution":{"iopub.status.busy":"2023-06-26T13:05:15.512629Z","iopub.execute_input":"2023-06-26T13:05:15.512911Z","iopub.status.idle":"2023-06-26T13:05:15.571537Z","shell.execute_reply.started":"2023-06-26T13:05:15.512887Z","shell.execute_reply":"2023-06-26T13:05:15.570454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = everythingScans_df.groupby(['Bone', 'Label']).apply(lambda x: x.sample(1)).reset_index(drop = True)\nfig, (m_axs) = plt.subplots(5, sub_df.shape[0]//4, figsize = (12, 12))\nfor c_ax, (_, c_row) in zip(m_axs.flatten(), sub_df.iterrows()):\n    c_ax.imshow(imread(c_row['path']), cmap = 'bone')\n    c_ax.axis('off')\n    c_ax.set_title('{Bone}:{Label}'.format(**c_row))","metadata":{"id":"I7cPhYnVF6b4","outputId":"c9a89215-8dde-46fb-b986-b67d28bf820a","execution":{"iopub.status.busy":"2023-06-26T13:05:15.574155Z","iopub.execute_input":"2023-06-26T13:05:15.575195Z","iopub.status.idle":"2023-06-26T13:05:17.445370Z","shell.execute_reply.started":"2023-06-26T13:05:15.575157Z","shell.execute_reply":"2023-06-26T13:05:17.444564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, loss_fn, optimizer, num_epochs=5, pretrained=False):\n\n    #put in training mode\n    model.train()\n    #reset model parameters\n    if not pretrained:\n        model.reset_parameters()\n\n\n    loss_history=[]\n    for epoch in range(num_epochs):\n        loss_per_epoch=0\n\n\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n\n        #batch computations\n        for i, (inputs, labels) in tqdm(enumerate(dataloader)):\n            inputs, labels=inputs.to(device), labels.to(device)\n            print(\"batch number\",i)\n\n            outputs=model(inputs).squeeze()\n            \n            #labels=labels.type_as(outputs) if type_=='softmax' else labels\n            #ouputs=outputs if type_=='softmax' else outputs.type_as(labels)\n            \n            #loss returns mean loss per batch unless specified otherwise\n\n            \n            batch_loss=loss_fn(outputs,labels)\n\n            #add the batch_loss to epoch loss\n            loss_per_epoch+=batch_loss.item()\n\n            optimizer.zero_grad()\n            #update parameters\n            batch_loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n            optimizer.step()\n            #print(i, loss.item())\n            # if i%8==0:\n            #     print(f\"Loss at iteration {i} is {round((loss_per_epoch/8),4)}\")\n            #     #loss_istory has acumulated the mean loss of 8 batches so we divide by 4 to get\n            #     # avg loss per batch\n            #     loss_history.append(round((loss_per_epoch/8),4))\n            #     loss_per_epoch=0\n            #if i % 9 == 0:\n                #print(f\"Cumuative Loss at batch {i} is {round((loss_per_epoch/9),4)}\")\n\n\n        print(f\"Loss at epoch {epoch+1} is {round((loss_per_epoch/len(dataloader)),4)}\")\n        loss_history.append(round((loss_per_epoch/len(dataloader)),4))\n    return loss_history\n\n@torch.no_grad()\ndef evaluate(model, dataloader, loss_fn, accuracy_fn, pretrained=False):\n    model.eval()\n\n    loss_history=[]\n    acc_history=[]\n    eval_loss=0\n    eval_acc=0\n\n    for i, (inputs, labels) in enumerate(dataloader):\n        #print(inputs.dtype,labels.dtype)\n        # if pretrained:\n        #     pass\n        # else:\n        #     inputs=inputs.view(inputs.shape[0],-1)\n        # if pretrained:\n        #     outputs=model(inputs).squeeze()\n        # else:\n        #     outputs=model(inputs)\n        inputs=inputs.to(device)\n        outputs=model(inputs).squeeze()\n        outputs=outputs.to(device)\n        #explain why\n        #labels=labels.type_as(outputs) if type_=='softmax' else labels\n        #ouputs=outputs if type_=='softmax' else outputs.type_as(labels)\n        labels=labels.to(device)\n        loss=loss_fn(outputs,labels)\n        eval_loss+=loss.item()\n        accuracy_fn.to(device)\n        accuracy_fn.update(outputs,labels)\n        print(\"accuracy is: \",accuracy_fn.compute())\n        #Binary accuracy returns the accuracy per batch\n        # eg if batch size is 32 and 25 are correct, it returns tensor(25/32)\n        eval_acc+=accuracy_fn.compute()\n\n        loss_history.append(round(loss.item(),4))\n    eval_loss=eval_loss/len(dataloader)\n    eval_acc=eval_acc/len(dataloader)\n    print(f\"\\n Test loss: {eval_loss:.5f}, Test acc: {eval_acc*100:.2f}%\\n\")\n    return loss_history","metadata":{"id":"r4v0DjjBF6b6","execution":{"iopub.status.busy":"2023-06-26T13:05:17.446425Z","iopub.execute_input":"2023-06-26T13:05:17.446771Z","iopub.status.idle":"2023-06-26T13:05:17.463897Z","shell.execute_reply.started":"2023-06-26T13:05:17.446742Z","shell.execute_reply":"2023-06-26T13:05:17.462951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import ResNet18_Weights\n\ntransformation_dict= {\n\n    'train':torchvision.transforms.Compose([]),\n\n    'train_resnet': torchvision.transforms.Compose(\n        [ResNet18_Weights.DEFAULT.transforms(),\n        torchvision.transforms.RandomAutocontrast(p=0.5),\n        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n    ]\n    )\n\n\n}\ntrain_df=pd.read_csv(os.path.join(csvpath,'MURA_fn_train.csv'),index_col=0)\ntrain_df['path']=murapath+train_df['path']\ntrain_df['path']=train_df['path'].replace({r'\\\\':'/'},regex=True)\ndev_df=pd.read_csv(os.path.join(csvpath,'MURA_fn_dev.csv'),index_col=0)\ndev_df['path']=murapath+dev_df['path']\ndev_df['path']=dev_df['path'].replace({r'\\\\':'/'},regex=True)\ndev_df['Split'].value_counts('valid')","metadata":{"id":"mq_MoHikF6b7","execution":{"iopub.status.busy":"2023-06-26T16:43:59.205362Z","iopub.execute_input":"2023-06-26T16:43:59.205982Z","iopub.status.idle":"2023-06-26T16:43:59.545934Z","shell.execute_reply.started":"2023-06-26T16:43:59.205946Z","shell.execute_reply":"2023-06-26T16:43:59.544881Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"train    1.0\nName: Split, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"train_dataloader=DataLoader(class6_Dataset(train_df, transform=transformation_dict['train_resnet']),\n                            batch_size=128,\n                            shuffle=True)\ntrain_features_batch, train_labels_batch = next(iter(train_dataloader))\nprint(train_features_batch.shape,train_labels_batch.shape)\n\ndev_dataloader=DataLoader(class6_Dataset(dev_df, transform=None),\n                            batch_size=128,\n                            shuffle=True)\ndev_features_batch,dev_labels_batch=next(iter(dev_dataloader))\nprint(dev_features_batch.shape,dev_labels_batch.shape)\n","metadata":{"id":"TR4dO_YXbyi0","outputId":"fde8eaa1-9f34-4016-8151-4bf8fffd3d28","execution":{"iopub.status.busy":"2023-06-26T13:05:17.804310Z","iopub.execute_input":"2023-06-26T13:05:17.804705Z","iopub.status.idle":"2023-06-26T13:05:22.694851Z","shell.execute_reply.started":"2023-06-26T13:05:17.804668Z","shell.execute_reply":"2023-06-26T13:05:22.693892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline\n","metadata":{}},{"cell_type":"code","source":"#replace itertools.cycle due to memory issues\ndef cycle(iterable):\n    iterator = iter(iterable)\n    while True:\n        try:\n            yield next(iterator)\n        except StopIteration:\n            iterator = iter(iterable)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T16:44:15.270908Z","iopub.execute_input":"2023-06-26T16:44:15.271344Z","iopub.status.idle":"2023-06-26T16:44:15.278185Z","shell.execute_reply.started":"2023-06-26T16:44:15.271308Z","shell.execute_reply":"2023-06-26T16:44:15.277078Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from itertools import islice\n@torch.no_grad()\ndef evaluate_2class(model, dataloader, loss_fn, accuracy_fn, pretrained=False,last_activation='sigmoid'):\n    model.eval()\n\n    eval_loss=0\n    eval_acc=0\n    last_activation = torch.nn.Sigmoid() if last_activation == 'sigmoid' else torch.nn.Softmax(dim=1)\n    \n    for i, (inputs, labels) in tqdm(enumerate(dataloader)):\n        inputs=inputs.to(device)\n        outputs=model(inputs).squeeze()\n        outputs=outputs.to(device)\n\n        labels=labels.to(device)\n        loss=loss_fn(outputs,labels)\n        eval_loss+=loss.item()\n        accuracy_fn.to(device)\n        print (\"eval outputs before sigmoid-softmax: \",outputs[:1])\n        outputs=last_activation(outputs)\n        print(\"eval ouputs after sigmoid-softmax: \", outputs[:1])\n        #Accuracy expects probabilities.\n        accuracy_fn.update(outputs,labels)\n        \n        eval_acc+=accuracy_fn.compute()\n\n    eval_loss=eval_loss/len(dataloader)\n    eval_acc=eval_acc/len(dataloader)\n    print(f\"\\n Test loss: {eval_loss:.5f}, Test acc: {eval_acc*100:.2f}%\\n\")\n    \n    return {\"eval_loss\": eval_loss,\"eval_acc\":eval_acc}\n\ndef train_2class(model, \n                 dataloader_train, \n                 dataloader_dev, \n                 loss_fn, \n                 optimizer, \n                 accuracy_fn, \n                 num_steps = 500,\n                 max_epochs = 10,\n                 eval_every = 10,\n                 eval_batches_sample = 2,\n                 pretrained=False,\n                last_activation = 'sigmoid',\n                early_stop_patience=False):\n\n    #put in training mode\n    model.train()\n    #reset model parameters\n    if not pretrained:\n        model.reset_parameters()\n\n    last_activation = torch.nn.Sigmoid() if last_activation == 'sigmoid' else torch.nn.Softmax(dim=1)\n    \n    loss_history=[]\n    accuracy_history=[]\n    loss_history_dev=[]\n    accuracy_history_dev=[]\n    \n    steps_iterator = iter(cycle(dataloader_train))\n    steps_iterator_dev = iter(cycle(dataloader_dev))\n    #for epoch in tqdm(range(num_epochs)):\n    \n    for steps in tqdm(range(min(num_steps//eval_every, len(dataloader_train)//eval_every))):\n        loss_per_epoch=0\n        running_accuracy=0.0\n        loss_per_epoch_dev=0\n        running_accuracy_dev=0.0\n\n        print(f\"Step {steps * eval_every}/{num_steps}\")\n        \n        #batch computations train\n        for train_step, (inputs, labels) in tqdm(enumerate(islice(steps_iterator, eval_every)), nrows=eval_every):\n            inputs, labels=inputs.to(device), labels.to(device)\n\n            outputs=model(inputs).squeeze()\n            \n            #loss returns mean loss per batch unless specified otherwise\n            batch_loss=loss_fn(outputs,labels)\n            #add the batch_loss to epoch loss\n            loss_per_epoch+=batch_loss.item()\n            outputs_sigmoid = last_activation(outputs)\n            accuracy_fn.to(device)\n            accuracy_fn.update(outputs_sigmoid,labels)\n            running_accuracy+=accuracy_fn.compute().cpu().item()\n            optimizer.zero_grad()\n            #update parameters\n            batch_loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n            optimizer.step()\n            \n            \n        \n        #compute validation stats\n        for dev_step, (inputs, labels) in enumerate(islice(steps_iterator_dev, eval_batches_sample)):\n            \n            inputs, labels=inputs.to(device), labels.to(device)\n\n            outputs=model(inputs).squeeze()\n            outputs_sigmoid = last_activation(outputs)\n            #loss returns mean loss per batch unless specified otherwise\n            batch_loss=loss_fn(outputs,labels)\n            #add the batch_loss to epoch loss\n            loss_per_epoch_dev+=batch_loss.item()\n            accuracy_fn.to(device)\n            accuracy_fn.update(outputs_sigmoid,labels)\n            running_accuracy_dev+=accuracy_fn.compute().cpu().item()\n\n        last_step_train = train_step + 1\n        last_step_dev = dev_step + 1 \n        \n        print(last_step_train, last_step_dev)\n        print(f\"Training Loss at epoch {steps+1} is {round((loss_per_epoch/last_step_train),4)}\")\n        loss_history.append(round((loss_per_epoch/last_step_train),4))\n        print(f\"Training Accuracy at epoch {steps+1} is {running_accuracy/last_step_train}\")\n        accuracy_history.append(running_accuracy/last_step_train)\n        print(f\"Validation Loss at epoch {steps+1} is {round((loss_per_epoch_dev/last_step_dev),4)}\")\n        loss_history_dev.append(round((loss_per_epoch_dev/last_step_dev),4))\n        print(f\"Validation Accuracy at epoch {steps+1} is {running_accuracy_dev/last_step_dev}\")\n        accuracy_history_dev.append(running_accuracy_dev/last_step_dev)\n        \n        #test early stopping\n        if early_stop_patience and len(accuracy_history_dev) > early_stop_patience:\n            if all([(acc > accuracy_history_dev[-1]) for acc in accuracy_history_dev[-early_stop_patience-1:-1]]):\n                print('Early stopping activated.')\n                break\n\n    \n    ret = {\"loss_history\":loss_history,\n           \"accuracy_history\":accuracy_history, \n           \"loss_history_dev\":loss_history_dev,\n           \"accuracy_history_dev\":accuracy_history_dev}\n        \n    \n    return ret\n\n#train_dataloader,dev_dataloader=get_loaders(train_df,train_df,0.1,class2_Dataset,transformation_dict,256)\n#results_train = train_2class(model, train_dataloader, dev_dataloader, loss_fn, optimizer, accuracy_fn, num_steps=30, eval_every=10, pretrained=True)\n","metadata":{"id":"r4v0DjjBF6b6","execution":{"iopub.status.busy":"2023-06-26T19:34:38.264144Z","iopub.execute_input":"2023-06-26T19:34:38.264585Z","iopub.status.idle":"2023-06-26T19:34:38.291029Z","shell.execute_reply.started":"2023-06-26T19:34:38.264549Z","shell.execute_reply":"2023-06-26T19:34:38.289816Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"train_dataloader,dev_dataloader=get_loaders(train_df,train_df,0.01,class2_Dataset,transformation_dict,256)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T13:06:33.220636Z","iopub.execute_input":"2023-06-26T13:06:33.221060Z","iopub.status.idle":"2023-06-26T13:06:38.024769Z","shell.execute_reply.started":"2023-06-26T13:06:33.221025Z","shell.execute_reply":"2023-06-26T13:06:38.022589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Not needed\ndef convert_t_to_list(history_list):\n    if not (torch.is_tensor(history_list[0])):\n        return history_list\n    else:\n        history_list_cpu=[t.cpu() for t in history_list ]\n        history_final=[t.numpy().item() for t in history_list_cpu]\n        return history_final","metadata":{"execution":{"iopub.status.busy":"2023-06-26T13:06:38.026821Z","iopub.execute_input":"2023-06-26T13:06:38.027180Z","iopub.status.idle":"2023-06-26T13:06:38.032848Z","shell.execute_reply.started":"2023-06-26T13:06:38.027143Z","shell.execute_reply":"2023-06-26T13:06:38.031850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#freeze all layers\n#use weights and default so as not to get warnings\n#use pretrained weights\ndef model_factory(last_layers=[(512,512),(512,1)]):\n    weights=torchvision.models.ResNet18_Weights.DEFAULT\n    resnet18 = torchvision.models.resnet18(weights=weights)\n    for param in resnet18.parameters():\n        param.requires_grad=False\n\n    weights.transforms()\n    in_features=resnet18.fc.in_features\n    #output only 1 value for binary classification\n    #the output is not passed through sigmoid\n    last_layer = torch.nn.Sequential(*[torch.nn.Linear(512,512),torch.nn.ReLU(),torch.nn.Linear(512,1)])\n    resnet18.fc=last_layer\n    return resnet18","metadata":{"id":"bXcTupfbF6b8","execution":{"iopub.status.busy":"2023-06-26T13:06:38.034398Z","iopub.execute_input":"2023-06-26T13:06:38.034995Z","iopub.status.idle":"2023-06-26T13:06:38.047238Z","shell.execute_reply.started":"2023-06-26T13:06:38.034964Z","shell.execute_reply":"2023-06-26T13:06:38.046259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T13:06:38.050951Z","iopub.execute_input":"2023-06-26T13:06:38.051695Z","iopub.status.idle":"2023-06-26T13:06:38.060537Z","shell.execute_reply.started":"2023-06-26T13:06:38.051670Z","shell.execute_reply":"2023-06-26T13:06:38.059563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn=torch.nn.BCEWithLogitsLoss(reduction='mean')\naccuracy_fn=torcheval.metrics.BinaryAccuracy(threshold=0.5)\nmodel=model_factory()\nmodel.to(device)\noptimizer=torch.optim.Adam(model.fc.parameters(),lr=0.01)\ntrain_df=everythingScans_df.loc[everythingScans_df['Split']=='train'].copy()\ntest_df=everythingScans_df.loc[everythingScans_df['Split']=='valid'].copy()\ntest_dataloader=DataLoader(class2_Dataset(test_df),batch_size=128,shuffle=True, drop_last = True)\ntrain_dataloader,dev_dataloader=get_loaders(train_df,train_df,1,class2_Dataset,transformation_dict,256)\n\nresults_train = train_2class(model, train_dataloader, dev_dataloader, loss_fn, optimizer, accuracy_fn, num_steps=500, eval_every=10, pretrained=True)\n\nresults_test = evaluate_2class(model, test_dataloader, loss_fn,accuracy_fn, pretrained=True)\n\n#train_accuracy_history=convert_t_to_list(train_accuracy_history)\n#train_loss_history=convert_t_to_list(train_loss_history)\n\nRESULTS  = [results_train]\nimport time\nnow = time.ctime().lower().replace(' ','_').replace(':','-')\ntorch.save(model,'/kaggle/working/t_models/simple_resnet_{}'.format(now))","metadata":{"id":"bXcTupfbF6b8","scrolled":true,"execution":{"iopub.status.busy":"2023-06-26T17:00:35.576479Z","iopub.execute_input":"2023-06-26T17:00:35.576865Z","iopub.status.idle":"2023-06-26T17:00:35.639667Z","shell.execute_reply.started":"2023-06-26T17:00:35.576834Z","shell.execute_reply":"2023-06-26T17:00:35.638040Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_fn\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mBCEWithLogitsLoss(reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m accuracy_fn\u001b[38;5;241m=\u001b[39mtorcheval\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mBinaryAccuracy(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_factory\u001b[49m()\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mparameters(),lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'model_factory' is not defined"],"ename":"NameError","evalue":"name 'model_factory' is not defined","output_type":"error"}]},{"cell_type":"code","source":"\nres1 = train_2class(model, train_dataloader, dev_dataloader, loss_fn, optimizer, accuracy_fn, num_steps=50, eval_every=10, pretrained=True)\nRESULTS.append(res1)\nevaluate_2class(model, test_dataloader, loss_fn,accuracy_fn, pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T15:02:21.382236Z","iopub.execute_input":"2023-06-26T15:02:21.382680Z","iopub.status.idle":"2023-06-26T15:04:25.273666Z","shell.execute_reply.started":"2023-06-26T15:02:21.382650Z","shell.execute_reply":"2023-06-26T15:04:25.272424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#change LR to 0.2\nfor g in optimizer.param_groups:\n    g['lr'] = 0.02\n","metadata":{"execution":{"iopub.status.busy":"2023-06-26T14:48:13.991935Z","iopub.execute_input":"2023-06-26T14:48:13.992292Z","iopub.status.idle":"2023-06-26T14:48:13.997650Z","shell.execute_reply.started":"2023-06-26T14:48:13.992263Z","shell.execute_reply":"2023-06-26T14:48:13.996569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"STEPS = 1500 \nnow = time.ctime().lower().replace(' ','_').replace(':','-')\n\nPATH = (\"/kaggle/working/t_models/simple_resnet_{}.pt\".format(now)) \nLOSS = results_train['loss_history'][-1]\ntorch.save({'steps': STEPS,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': LOSS,\n            },PATH)\nprint(f'saved at {PATH}')","metadata":{"execution":{"iopub.status.busy":"2023-06-26T15:00:11.705840Z","iopub.execute_input":"2023-06-26T15:00:11.706263Z","iopub.status.idle":"2023-06-26T15:00:11.793289Z","shell.execute_reply.started":"2023-06-26T15:00:11.706233Z","shell.execute_reply":"2023-06-26T15:00:11.792249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Two task training\n","metadata":{}},{"cell_type":"code","source":"from torchmetrics import Accuracy\n\n#PHASE 1 ...\n#start training with 6 classes\n\ntrain_dataloader,dev_dataloader=get_loaders(train_df,dev_df,0.1,class6_Dataset,transformation_dict,256)\n#loss expects unnormalised logits\nloss_fn=torch.nn.CrossEntropyLoss(reduction='mean')\nSTEPS=100\nmodel = ResnetTransfer(train_resnet=True)\nmodel.to(device)\noptimizer=torch.optim.Adam(model.parameters(),lr=0.05)\naccuracy_fn=Accuracy(task='multiclass', average='macro', num_classes=7,threshold=0.5)\nresults_train=train_2class(model, \n                     train_dataloader, \n                     dev_dataloader, \n                     loss_fn, \n                     optimizer, \n                     accuracy_fn, \n                     num_steps=STEPS, \n                     eval_every=10, \n                     pretrained=True,\n                    last_activation='softmax',\n                    early_stop_patience=4)\n#results_test=train_2class(model, dev_dataloader, loss_fn,accuracy_fn, pretrained=True)","metadata":{"id":"ZxeyjbFRF6b7","outputId":"347d7442-1903-4c5e-b5d7-138065cb915b","execution":{"iopub.status.busy":"2023-06-26T19:34:46.198390Z","iopub.execute_input":"2023-06-26T19:34:46.198764Z","iopub.status.idle":"2023-06-26T19:35:42.538761Z","shell.execute_reply.started":"2023-06-26T19:34:46.198713Z","shell.execute_reply":"2023-06-26T19:35:42.537745Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"torch.Size([128, 3, 224, 224]) torch.Size([128])\ntorch.Size([128, 3, 224, 224]) torch.Size([128])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab1c2f372bcc4f63abd16068f5a6cc6c"}},"metadata":{}},{"name":"stdout","text":"Step 0/100\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5a0c9580e742109244cb962c69c182"}},"metadata":{}},{"name":"stdout","text":"10 2\nTraining Loss at epoch 1 is 1.8932\nTraining Accuracy at epoch 1 is 0.16145563572645188\nValidation Loss at epoch 1 is 1.8948\nValidation Accuracy at epoch 1 is 0.1646108627319336\nStep 10/100\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76a3a180404943bebb7c5b950651cf4f"}},"metadata":{}},{"name":"stdout","text":"10 2\nTraining Loss at epoch 2 is 1.8697\nTraining Accuracy at epoch 2 is 0.16909753978252412\nValidation Loss at epoch 2 is 1.9072\nValidation Accuracy at epoch 2 is 0.1730717420578003\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nnow = time.ctime().lower().replace(' ','_').replace(':','-')\nRESULTS = [results]\nPATH = (\"/kaggle/working/t_models/simple_resnet_{}.pt\".format(now)) \nLOSS = results['loss_history'][-1]\ntorch.save({'steps': 2,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': LOSS,\n            'results_history':[results]\n            },PATH)\nprint(f'saved at {PATH}')","metadata":{"execution":{"iopub.status.busy":"2023-06-26T19:33:31.208402Z","iopub.status.idle":"2023-06-26T19:33:31.208763Z","shell.execute_reply.started":"2023-06-26T19:33:31.208580Z","shell.execute_reply":"2023-06-26T19:33:31.208596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_results = train2class(....)\n\nRESULTS.append(new_results)\n\nimport time\nnow = time.ctime().lower().replace(' ','_').replace(':','-')\n\nPATH = (\"/kaggle/working/t_models/simple_resnet_{}.pt\".format(now)) \nLOSS = results['loss_history'][-1]\ntorch.save({'steps': 2,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': LOSS,\n            'results_history':[results]\n            },PATH)\nprint(f'saved at {PATH}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_test=evaluate_2class(model, dev_dataloader, loss_fn,accuracy_fn, pretrained=True,last_activation='softmax')","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:52:44.196211Z","iopub.execute_input":"2023-06-26T18:52:44.196614Z","iopub.status.idle":"2023-06-26T18:52:48.358709Z","shell.execute_reply.started":"2023-06-26T18:52:44.196578Z","shell.execute_reply":"2023-06-26T18:52:48.357749Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e567118f0145413795d915ec3f16bcd6"}},"metadata":{}},{"name":"stdout","text":"eval outputs before sigmoid-softmax:  tensor([[0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([[0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118]],\n       device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([[0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([[0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118]],\n       device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([[0., 0., 0., 0., 0., 0., 1.]], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([[0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.1147, 0.3118]],\n       device='cuda:0')\n\n Test loss: 1.85925, Test acc: 14.55%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"os.listdir('/kaggle/working/t_models')\nmodel=torch.load('/kaggle/working/t_models/resnet_2phase_fri_jun_23_18-16-17_2023')\nmodel","metadata":{"execution":{"iopub.status.busy":"2023-06-26T11:52:14.643630Z","iopub.status.idle":"2023-06-26T11:52:14.644353Z","shell.execute_reply.started":"2023-06-26T11:52:14.644090Z","shell.execute_reply":"2023-06-26T11:52:14.644113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PHASE 2 ...\n# Now we use 2 classes negative and positive\ntrain_dataloader,dev_dataloader=get_loaders(train_df,dev_df,0.05,class2_Dataset,transformation_dict,128)\nmodel.trigger_phase2()\nmodel.to(device)\n#Now we only have 2 classes\n# Loss to input is not passed through sigmoid \nloss_fn=torch.nn.BCEWithLogitsLoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=0.001)\naccuracy_fn=Accuracy(task='binary', num_classes=2,threshold=0.5)\nclass2_results=train_2class(model, \n                     train_dataloader, \n                     dev_dataloader, \n                     loss_fn, \n                     optimizer, \n                     accuracy_fn, \n                     num_steps=20, \n                     eval_every=10, \n                     pretrained=True,\n                    last_activation='sigmoid')\n#dev_loss_history=evaluate(model, dev_dataloader, loss_fn,accuracy_fn, pretrained=True)","metadata":{"id":"ZxeyjbFRF6b7","outputId":"347d7442-1903-4c5e-b5d7-138065cb915b","execution":{"iopub.status.busy":"2023-06-26T18:52:56.713056Z","iopub.execute_input":"2023-06-26T18:52:56.713424Z","iopub.status.idle":"2023-06-26T18:53:24.103589Z","shell.execute_reply.started":"2023-06-26T18:52:56.713392Z","shell.execute_reply":"2023-06-26T18:53:24.102597Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"torch.Size([128, 3, 224, 224]) torch.Size([128])\ntorch.Size([128, 3, 224, 224]) torch.Size([128])\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"becb81c5eb714c9abb11a1af8cc7c31a"}},"metadata":{}},{"name":"stdout","text":"Step 0/20\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a746eb5057c476fb291839047ffb337"}},"metadata":{}},{"name":"stdout","text":"10 2\nTraining Loss at epoch 1 is 0.7154\nTraining Accuracy at epoch 1 is 0.40829086005687715\nValidation Loss at epoch 1 is 0.6966\nValidation Accuracy at epoch 1 is 0.4025377929210663\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df=everythingScans_df.loc[everythingScans_df['Split']=='valid'].copy()\ntest_dataloader=DataLoader(class2_Dataset(test_df),batch_size=128,shuffle=True, drop_last = True)\nclass2_results_test=results_test=evaluate_2class(model, test_dataloader, loss_fn,accuracy_fn, pretrained=True,last_activation='sigmoid')","metadata":{"execution":{"iopub.status.busy":"2023-06-26T18:54:19.388082Z","iopub.execute_input":"2023-06-26T18:54:19.388471Z","iopub.status.idle":"2023-06-26T18:54:51.828659Z","shell.execute_reply.started":"2023-06-26T18:54:19.388438Z","shell.execute_reply":"2023-06-26T18:54:51.827685Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66f57061d11d46bfa00812df2a95f608"}},"metadata":{}},{"name":"stdout","text":"eval outputs before sigmoid-softmax:  tensor([0.0405], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5101], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0367], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5092], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([2.1393e-05], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5000], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0408], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5102], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0362], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5090], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0340], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5085], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0393], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5098], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0351], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5088], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0414], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5103], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0319], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5080], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([2.5646e-09], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5000], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0411], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5103], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0395], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5099], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0410], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5103], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0404], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5101], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0401], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5100], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0414], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5104], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0393], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5098], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([5.1106e-13], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5000], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0327], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5082], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0411], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5103], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0320], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5080], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([2.1386e-07], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5000], device='cuda:0')\neval outputs before sigmoid-softmax:  tensor([0.0403], device='cuda:0')\neval ouputs after sigmoid-softmax:  tensor([0.5101], device='cuda:0')\n\n Test loss: 0.69375, Test acc: 44.27%\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\n\nimport time\nnow = time.ctime().lower().replace(' ','_').replace(':','-')\ntorch.save(model,'/kaggle/working/t_models/resnet_2phase_{}'.format(now))","metadata":{"id":"ZxeyjbFRF6b7","outputId":"347d7442-1903-4c5e-b5d7-138065cb915b","execution":{"iopub.status.busy":"2023-06-26T11:52:14.645672Z","iopub.status.idle":"2023-06-26T11:52:14.646392Z","shell.execute_reply.started":"2023-06-26T11:52:14.646128Z","shell.execute_reply":"2023-06-26T11:52:14.646151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.plot(train_loss_history, label='train')\n\n#plt.plot(dev_loss_history, label='valid')","metadata":{"id":"9h2tSEZHF6b8","outputId":"38672255-6a13-4356-8ce4-79ec46edf300","execution":{"iopub.status.busy":"2023-06-26T11:52:14.647783Z","iopub.status.idle":"2023-06-26T11:52:14.648617Z","shell.execute_reply.started":"2023-06-26T11:52:14.648338Z","shell.execute_reply":"2023-06-26T11:52:14.648364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_accuracy_history=convert_t_to_list(train_accuracy_history)\ntrain_loss_history=convert_t_to_list(train_loss_history)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T11:52:14.650016Z","iopub.status.idle":"2023-06-26T11:52:14.650817Z","shell.execute_reply.started":"2023-06-26T11:52:14.650573Z","shell.execute_reply":"2023-06-26T11:52:14.650596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCH = 10 \nPATH = (\"/kaggle/working/t_models/frozen_resnet_{}.pt\".format(now)) \nLOSS = train_loss_history[-1] \ntorch.save({'epoch': EPOCH,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': LOSS,\n            },PATH)\nprint(f'saved at {PATH}')","metadata":{"id":"bXcTupfbF6b8","execution":{"iopub.status.busy":"2023-06-26T11:52:14.652242Z","iopub.status.idle":"2023-06-26T11:52:14.652974Z","shell.execute_reply.started":"2023-06-26T11:52:14.652687Z","shell.execute_reply":"2023-06-26T11:52:14.652709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH='/kaggle/working/t_models/frozen_resnet_sat_jun_24_10-57-15_2023.pt'\nmodel = model_factory().to(device)\noptimizer=torch.optim.Adam(model.fc.parameters(),lr=0.001)\ncheckpoint = torch.load(PATH)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\nmodel.eval()# - or -model.train()\ntest_loss_history,test_accuracy_history=evaluate_2class(model, test_dataloader, loss_fn,accuracy_fn, pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-26T11:52:14.654320Z","iopub.status.idle":"2023-06-26T11:52:14.655032Z","shell.execute_reply.started":"2023-06-26T11:52:14.654771Z","shell.execute_reply":"2023-06-26T11:52:14.654794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_loss_history,label='train_loss')\nplt.plot(train_accuracy_history, label='train_acc')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-26T11:52:14.656390Z","iopub.status.idle":"2023-06-26T11:52:14.657113Z","shell.execute_reply.started":"2023-06-26T11:52:14.656861Z","shell.execute_reply":"2023-06-26T11:52:14.656894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}